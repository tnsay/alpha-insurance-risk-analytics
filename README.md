# ğŸš— Alpha Insurance Risk Analytics â€“ EDA and Modeling

Welcome to the repository for analyzing insurance risk data as part of the **Alpha Analytics Project**.  
This `task-1` branch focuses on **Exploratory Data Analysis (EDA)** and initial insights from a large dataset of insurance transactions.

---

## ğŸ“Œ Project Overview

**Objective**: Perform EDA, identify risk patterns, and prepare data for modeling claim severity.  
**Data Size**: ~1 million records  
**Core Features**:
- `TotalPremium`, `TotalClaims`, `SumInsured`, `CustomValueEstimate`
- `TransactionMonth`, `Province`, `CoverType`, `AutoMake`

---

## ğŸ” Task 1 â€“ Exploratory Data Analysis (EDA)

### âœ… Descriptive Statistics
- Used `.describe()` to summarize major numerical features.
- Checked variability via standard deviation.
- Verified and cleaned data types (e.g., datetime parsing).

### âœ… Data Quality Checks
- Reported missing values and handled them.
- Ensured clean formatting for categorical fields.

### âœ… Univariate Analysis
- Histograms for `TotalPremium`, `TotalClaims`, `SumInsured`
- Bar plots for `Province`, `CoverType`, `AutoMake`

### âœ… Bivariate / Multivariate Trends
- Monthly trends: `Total Claims` vs `Total Premiums`
- Tracked claim frequency over time
- Multi-line charts by `Province` revealed regional patterns

### âœ… Outlier Detection
- Box plots used to flag outliers in key numeric fields

### âœ… Geographical Insights
- Compared Cover Type, Auto Make, and Premiums across provinces

---

## ğŸ“¸ Visualizations

1. ğŸ“‰ **Monthly Premiums vs Claims**  
   _Visualizes business volume trends over time._

2. ğŸ“ˆ **Claim Frequency by Month**  
   _Tracks how often claims occur monthly._

3. ğŸŒ **Claims by Province**  
   _Exposes regional risk distribution._

---

## ğŸ“ Repository Structure

â”‚
â”œâ”€â”€ insurance_eda.ipynb # Main notebook with all EDA steps
â”œâ”€â”€ README.md # This file
â”œâ”€â”€ assets/ # Plots and images from the analysis
â””â”€â”€ data/ # Cleaned or raw input datasets


---

## ğŸ§ª Task 2 â€“ Data Version Control (DVC)

- Initialized DVC for reproducible data pipelines  
- Tracked `raw_data.csv`, `cleaned_data.csv`, and derived KPIs  
- Local DVC remote set at `C:/dvc_storage`  
- Integrated DVC with Git for versioned data and models

---

## ğŸ“Š Task 3 â€“ Statistical Risk Hypotheses

- âœ… **Provinces**: _Statistically significant differences_ in claim frequency and severity (p < 0.001)  
  â¤ *E.g., Gauteng shows ~15% higher loss ratio than Western Cape*

- âŒ **Gender**: No significant difference (p > 0.8)  
  â¤ *Gender shouldn't be a pricing factor*

---

## ğŸ¤– Task 4 â€“ Model Interpretability

### ğŸ”§ Model Summary
- **Trained Model**: XGBoost Regressor  
- **Target**: `ClaimSeverity` (for claims only)  
- **Features**: Cleaned + encoded policy data  

### ğŸ§  SHAP for Model Explainability
```python
import shap
explainer = shap.Explainer(xgb, X_test)
shap_values = explainer(X_test)
shap.summary_plot(shap_values, X_test, max_display=10)

Model saving
import joblib
joblib.dump(xgb, "xgb_claim_severity_model.pkl")
## ğŸ§‘â€ğŸ’» Author

Created by Tinsae Dagne
For Alpha Analytics Risk Project â€“ Week 3